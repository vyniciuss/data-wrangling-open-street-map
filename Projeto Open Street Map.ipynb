{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpando dados do OpenStreetMap com MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral do projeto\n",
    "\n",
    "\n",
    "Para realizar a limpeza dos dados, foi escolhida a área de Boston, EUA,  no https://www.openstreetmap.org e utilizado as técnicas de tratamento para avaliar a qualidade dos dados para validade, precisão, plenitude, consistência e uniformidade. Por último, foi escolhido MongoDB como modelo para armazenamento dos dados limpos, para, enfim, realizar análise exploratória nos dados.\n",
    "\n",
    "Area do Mapa: Boston, EUA\n",
    "\n",
    "\n",
    "https://www.openstreetmap.org/export#map=12/42.3677/-71.0458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Auditoria de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "osm_file = os.path.join(\"\", \"boston.osm\")\n",
    "\n",
    "# ================================================== #\n",
    "#                Regex Expressions                   #\n",
    "# ================================================== #\n",
    "# somente contém letras minúsculas e válidas.\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "# para tags válidas com dois pontos no valor.\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "# para tags com caracteres problemáticos.\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "# procura por padrões de escrita de endereços no final do texto\n",
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "# para códigos postais válidos\n",
    "postal_code_re = re.compile(r'^[0-9]{5}(?:-[0-9]{4})?$', re.IGNORECASE)\n",
    "# ================================================== #\n",
    "#               Load Properties                    #\n",
    "# ================================================== #\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Highway\"]\n",
    "\n",
    "mapping_street = { \"Ave\" :  \"Avenue\",\n",
    "                    \"Ave.\" : \"Avenue\",\n",
    "                    \"Ct\" :   \"Court\",\n",
    "                    \"Hwy\" :  \"Highway\",\n",
    "                    \"Park\" : \"Parkway\",\n",
    "                    \"Pkwy\" : \"Parkway\",\n",
    "                    \"Pl\" :   \"Place\",\n",
    "                    \"Rd\" :   \"Road\",\n",
    "                    \"Sq.\" :  \"Square\",\n",
    "                    \"St\" :   \"Street\",\n",
    "                    \"st.\" :  \"Street\",\n",
    "                    \"ST\" :   \"Street\",\n",
    "                    \"St\" :   \"Street\",\n",
    "                    \"St.\" :  \"Street\",\n",
    "                    \"St,\" :  \"Street\",\n",
    "                    \"Cambrdige\": \"Cambridge\",\n",
    "                    \"MA\":    \"Massachusetts\"\n",
    "                  }\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file,  tags=('node', 'way', 'relation', 'tag'), verify_tags = False):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end':\n",
    "            if verify_tags:\n",
    "                if elem.tag in tags:\n",
    "                    yield elem\n",
    "                    root.clear()\n",
    "            else:\n",
    "                yield elem\n",
    "                root.clear()\n",
    "\n",
    "                \n",
    "def print_sorted_dict(dictionary):\n",
    "    keys = dictionary.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for key in keys:\n",
    "        value = dictionary[key]\n",
    "        print(\"%s: %d\" % (key, value))\n",
    "        \n",
    "def audit_count_values(dictionary, value, pattern_regex):\n",
    "    \"\"\"Pesquisa os padrões de escrita e quantidade de ocorrência dos mesmos.\n",
    "    \n",
    "    Preenche o dicionário informado onde a chave será o padrão encontrado \n",
    "    e o valor será a soma das ocorrências encontradas.\n",
    "    \n",
    "    Args: \n",
    "        dictionary: Dicionário com os padrões de escrita.\n",
    "        value:  Valor que será verificado.\n",
    "    \n",
    "    \"\"\"\n",
    "    m = pattern_regex.search(value)\n",
    "    if m:\n",
    "        value_type = m.group()\n",
    "        dictionary[value_type] += 1\n",
    "        \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_postal_code(elem):\n",
    "    return elem.attrib['k'] == \"addr:postcode\"\n",
    "\n",
    "def is_valid_tag(elem):\n",
    "    \"\"\"Verifica se a tag é válida.\n",
    "    \n",
    "    A tag só é válida se possuir os atributos K e V e se não possuir \n",
    "    caracteres inválidos no atributo K\n",
    "    \n",
    "    \"\"\"\n",
    "    value = problemchars.search(elem.get('k'))\n",
    "    return value == None and 'k' in elem.attrib and 'v' in elem.attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ####   1.1 Para ter um maior entendimento sobre os dados, realizei um processamento para descobrir quais e quantas tags existem no arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 36052,\n",
      " 'meta': 1,\n",
      " 'nd': 421429,\n",
      " 'node': 335386,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 735,\n",
      " 'tag': 187491,\n",
      " 'way': 54602}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    \"\"\"\n",
    "    Percorre a ávore de elementos em buscas da quantidade de tags \n",
    "    que o arquivo possui.\n",
    "    \n",
    "    Args: \n",
    "        filename: O arquivo que será análisado.\n",
    "    \n",
    "    Returns: \n",
    "        Um dicionário com o nome da tag como chave e o total\n",
    "        de registros encontrados.\n",
    "        \n",
    "        {'bounds': 1,\n",
    "         'member': 36052,\n",
    "         'meta': 1,\n",
    "         'nd': 421429}\n",
    "        \n",
    "    \"\"\"\n",
    "    tags = {}\n",
    "    for element in get_element(osm_file, verify_tags = False):\n",
    "        if element.tag not in tags.keys():\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "    \n",
    "\n",
    "tags = count_tags(osm_file)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    1.2 A função a seguir, tem a intenção de verificar se existe algum problema no valor de \"k\" para cada \"tag\" no arquivo. Para isso, será utilizado três expressões regulares para identificar padrões nos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 148488, 'lower_colon': 30911, 'other': 8092, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "def key_type(element, keys):\n",
    "    \"\"\" Conta a quantidade de padrões encontrados em \"K\".\n",
    "     \n",
    "    Para cada valor encontrado em K, soma-se 1 ao seu \n",
    "    padrão correspondente.\n",
    "    \n",
    "    Args: \n",
    "        element: O elemento que será análisado.\n",
    "        keys: dicionário com os padrões esperados.\n",
    "    \n",
    "    Returns: \n",
    "        Um dicionário com nome do padrão e o total de ocorrências encontradas.\n",
    "        \n",
    "        {'lower': 148488, 'lower_colon': 30911, 'other': 8092, 'problemchars': 0}\n",
    "        \n",
    "    \"\"\"\n",
    "    if lower.match(element.attrib['k']):\n",
    "        keys['lower'] += 1\n",
    "    elif lower_colon.match(element.attrib['k']):\n",
    "        keys['lower_colon'] += 1\n",
    "    elif problemchars.search(element.attrib['k']):\n",
    "        keys['problemchars'] += 1\n",
    "    else:\n",
    "        keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    \"\"\" Processa os dados em busca de padrões no valor de \"K\".\n",
    "     \n",
    "    Define um dicionário com os padrões dos dados esperados em \"K\" \n",
    "    e percorre a ávore de elementos em buscas da quantidade de \n",
    "    itens que se encaixem nos padrões.\n",
    "    \n",
    "    Padrões dos valores esperados em K:\n",
    "    \n",
    "        - lower: somente contém letras minúsculas e válidas.\n",
    "        - lower_colon: para tags válidas com dois pontos no valor.\n",
    "        - problemchars: para tags com caracteres problemáticos.\n",
    "        - other: para outras tags que não se enquadrem nas outras três\n",
    "                 categorias.\n",
    "    \n",
    "    Args: \n",
    "        filename: O arquivo que será análisado.\n",
    "    \n",
    "    Returns: \n",
    "        Um dicionário com nome do padrão e o total de ocorrências encontradas.\n",
    "        \n",
    "        {'lower': 148488, 'lower_colon': 30911, 'other': 8092, 'problemchars': 0}\n",
    "        \n",
    "    \"\"\"\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for element in get_element(osm_file, tags=('tag'), verify_tags = True):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map(osm_file)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 A próxima tarefa é identificar quantos usuários contribuíram com o mapa de Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931 usuários contribuíram na região de Boston. \n"
     ]
    }
   ],
   "source": [
    "def get_user(element):\n",
    "    \"\"\"Recupera o usuário que contribuiu com o mapa.\n",
    "    \n",
    "    Args: \n",
    "        element: O elemento que será análisado.\n",
    "    \n",
    "    Returns: \n",
    "        O identificador do usuário encontrado\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if element.get('uid'):\n",
    "        uid = element.attrib[\"uid\"]\n",
    "        return uid\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map_user(filename):\n",
    "    \"\"\" Processa os dados em busca dos usuários que contribuíram com os dados.\n",
    "     \n",
    "    Para para cada tag (node, way, relation) encontrada, recupera o usuário e adiona em um set.\n",
    "\n",
    "    Args: \n",
    "        filename: O arquivo que será análisado.\n",
    "    \n",
    "    Returns: \n",
    "        Um set com os usuários encontrados.\n",
    "        \n",
    "        {'100042', '100049', '100054'}\n",
    "        \n",
    "    \"\"\"\n",
    "    users = set()\n",
    "    for element in get_element(osm_file, tags=('node', 'way', 'relation'), verify_tags = True):\n",
    "        if get_user(element):\n",
    "             users.add(get_user(element))\n",
    "\n",
    "    return users\n",
    "\n",
    "users = process_map_user(osm_file)\n",
    "print( '{} usuários contribuíram na região de Boston. '.format(len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 A ideia da função a seguir é identificar os diferentes padrões de escrita dos nomes das ruas e quantas vezes ocorreram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1302: 1\n",
      "#501: 1\n",
      "1100: 1\n",
      "1702: 1\n",
      "1900: 1\n",
      "3: 1\n",
      "303: 1\n",
      "500: 1\n",
      "6: 1\n",
      "Ave: 147\n",
      "Ave.: 21\n",
      "Avenue: 419\n",
      "Boulevard: 7\n",
      "Boylston: 1\n",
      "Broadway: 33\n",
      "Building: 1\n",
      "Cambrdige: 2\n",
      "Center: 8\n",
      "Court: 7\n",
      "Ct: 8\n",
      "Drive: 55\n",
      "Driveway: 1\n",
      "Elm: 1\n",
      "floor: 2\n",
      "Garage: 1\n",
      "Hall: 1\n",
      "Hampshire: 1\n",
      "Highway: 8\n",
      "Hwy: 1\n",
      "Lafayette: 1\n",
      "Lane: 1\n",
      "LEVEL: 1\n",
      "Market: 1\n",
      "Park: 16\n",
      "Parkway: 2\n",
      "Pkwy: 10\n",
      "Pl: 1\n",
      "Place: 55\n",
      "Plaza: 3\n",
      "Rd: 23\n",
      "Road: 50\n",
      "Row: 21\n",
      "South: 1\n",
      "Sq.: 1\n",
      "Square: 49\n",
      "St: 216\n",
      "st: 1\n",
      "ST: 1\n",
      "St,: 1\n",
      "St.: 32\n",
      "Street: 1547\n",
      "Terrace: 10\n",
      "Way: 27\n",
      "Wharf: 5\n",
      "Windsor: 2\n",
      "Winsor: 1\n",
      "Yard: 1\n"
     ]
    }
   ],
   "source": [
    "street_types = defaultdict(int)\n",
    " \n",
    "def audit_street_occurrences(filename, pattern_regex):\n",
    "    \"\"\"Realiza auditoria nos padrões dos nomes das ruas cadastrados.\n",
    "    \n",
    "    \n",
    "     Args: \n",
    "        filename: O arquivo que será análisado.\n",
    "        pattern_regex: padrão que será pesquisado.\n",
    "    \"\"\"\n",
    "    for elem in get_element(filename, tags=('tag'), verify_tags = True):\n",
    "        if is_street_name(elem):\n",
    "            audit_count_values(street_types, elem.attrib['v'], pattern_regex)    \n",
    "    print_sorted_dict(street_types)\n",
    "   \n",
    "\n",
    "audit_street_occurrences(osm_file, street_type_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 A próxima função realizará uma auditoria nos códigos postais a fim de identificar possíveis problemas.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram encontrados 1717 códigos postais válidos\n",
      "---------------------------------------------------------------------------------------\n",
      "|Exemplo de códigos válidos encontrados ['02110', '02114', '02116', '02116', '02116'] \n",
      "---------------------------------------------------------------------------------------\n",
      "Foram encontrados 4 códigos postais inválidos.\n",
      "---------------------------------------------------------------------------------------\n",
      "|Exemplo de códigos inválidos encontrados ['MA', 'MA 02116', 'MA 02135', 'MA'] \n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "postal_codes_types = {\"Válidos\": [], \"Inválidos\" : []}\n",
    "\n",
    "def audit_postal_code(filename, pattern_regex):\n",
    "    \"\"\"Realiza auditoria nos padrões dos códigos postais cadastrados.\n",
    "        \n",
    "    Args: \n",
    "        filename: O arquivo que será análisado.\n",
    "        pattern_regex: padrão que será pesquisado.\n",
    "        \n",
    "    \"\"\"\n",
    "    for elem in get_element(filename, tags=('tag'), verify_tags = True):\n",
    "        if is_postal_code(elem):\n",
    "            value = elem.get('v')\n",
    "            if pattern_regex.match(value):\n",
    "                postal_codes_types[\"Válidos\"].append(value)\n",
    "            else:\n",
    "                postal_codes_types[\"Inválidos\"].append(value)\n",
    "                \n",
    "    print('Foram encontrados {} códigos postais válidos'.format(len(postal_codes_types[\"Válidos\"])))\n",
    "    print('---------------------------------------------------------------------------------------')\n",
    "    print('|Exemplo de códigos válidos encontrados {} '.format(postal_codes_types[\"Válidos\"][0:5]))\n",
    "    print('---------------------------------------------------------------------------------------')\n",
    "    print('Foram encontrados {} códigos postais inválidos.'.format(len(postal_codes_types[\"Inválidos\"])))\n",
    "    print('---------------------------------------------------------------------------------------')\n",
    "    print('|Exemplo de códigos inválidos encontrados {} '.format(postal_codes_types[\"Inválidos\"]))\n",
    "    print('---------------------------------------------------------------------------------------')\n",
    "\n",
    "audit_postal_code(osm_file, postal_code_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Problemas Encontrados.\n",
    "\n",
    "Após coletar os dados do Open Street Map, resolvi realizar uma rápida auditoria nos dados, especificamente nos dados de endereço, e foi detectado dois problemas que precisam ser resolvidos antes de registrar os dados no MongoDB.\n",
    "- Diversas abreviações para o mesmo endereço (Street = St, st, ST, St, St)\n",
    "- Códigos postais inválidos ('MA', 'MA 02116', 'MA 02135', 'MA')\n",
    "\n",
    "#### 2.1 Diversas abreviações para o mesmo endereço.\n",
    "\n",
    "Para resolver os problemas de abreviações, foi necessário definir uma lista com os valores desejadas, para realizar a substituição dos valores problemáticos. Para isso, foi utilizada o bloco de código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somerville Ave => Somerville Avenue\n",
      "Massachusetts Ave => Massachusetts Avenue\n",
      "Commonwealth Ave => Commonwealth Avenue\n",
      "Josephine Ave => Josephine Avenue\n",
      "Highland Ave => Highland Avenue\n",
      "Everett Ave => Everett Avenue\n",
      "Francesca Ave => Francesca Avenue\n",
      "Lexington Ave => Lexington Avenue\n",
      "Morrison Ave => Morrison Avenue\n",
      "Mystic Ave => Mystic Avenue\n",
      "College Ave => College Avenue\n",
      "Concord Ave => Concord Avenue\n",
      "Willow Ave => Willow Avenue\n",
      "Western Ave => Western Avenue\n",
      "Massachusetts Ave. => Massachusetts Avenue\n"
     ]
    }
   ],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    \"\"\"Identifica os padrões de escrita dos endereços e separa em um dicinário. \n",
    "    \n",
    "    Args: \n",
    "        street_types: Dicionário que separará os padrões encontrados.\n",
    "        street_name: endereço que será categorizado.\n",
    "        \n",
    "    \"\"\"\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def audit_street_standardization(osmfile):\n",
    "    \"\"\"Realiza auditoria nos padrões dos nomes das ruas cadastrados.\n",
    "    \n",
    "    Args: \n",
    "        osmfile: arquivo que será analisado.\n",
    "        \n",
    "    Returns: \n",
    "        Dicionário onde cada padrão encontrado será uma chave e o valor será um\n",
    "        set dos endereços enquadrados no padrão.\n",
    "        \n",
    "    \"\"\"\n",
    "    street_types = defaultdict(set)\n",
    "    for elem in get_element(osm_file, tags=('tag', 'way'), verify_tags = True):\n",
    "        if 'k' in elem.attrib and is_street_name(elem):\n",
    "            audit_street_type(street_types, elem.get('v'))\n",
    "    \n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    \"\"\"Atualiza o endereço com problema pelo valor padronizado.\n",
    "    \n",
    "    As abreviações encontradas serão substituídas pelos valores completos.\n",
    "    \n",
    "    Args: \n",
    "        name: endereço.\n",
    "        mapping: dicionário com os valores desejados.\n",
    "        \n",
    "    Returns: \n",
    "        Se o endereço informado tiver uma abreviação, então terá seu valor \n",
    "        substituído pelo valor completo.\n",
    "    \n",
    "    \"\"\"\n",
    "    #remove valor indevido\n",
    "    name = name.replace(\"#\", \"\")\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type in mapping.keys():\n",
    "                name = re.sub(street_type_re, mapping[street_type], name)\n",
    "    return name\n",
    "\n",
    "st_types = audit_street_standardization(osm_file)\n",
    "\n",
    "cont = 0\n",
    "for st_type, ways in st_types.items():\n",
    "    for name in ways:\n",
    "        if cont == 15:\n",
    "            break\n",
    "        better_name = update_name(name, mapping_street)\n",
    "        print( name, \"=>\", better_name)\n",
    "        cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Códigos postais inválidos.\n",
    "\n",
    "Para entender melhor o problema, os códigos postais nos EUA possuem 2 formatos: com 5 dígitos(12345) e com 9 dígitos(12345-6789), mas nenhuma letra é permitida. Como encontramos códigos postais com letras, desenvolvemos a solução abaixo para a limpeza dos dados sujos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02110 => 02110\n",
      "02114 => 02114\n",
      "02116 => 02116\n",
      "02116 => 02116\n",
      "02116 => 02116\n",
      "02144 => 02144\n",
      "02138 => 02138\n",
      "02139 => 02139\n",
      "02140 => 02140\n",
      "02116 => 02116\n",
      "02142 => 02142\n",
      "02139 => 02139\n",
      "02139 => 02139\n",
      "02143 => 02143\n",
      "02210 => 02210\n"
     ]
    }
   ],
   "source": [
    "def update_postal_code(value):\n",
    "    \"\"\"Atualiza o código postal com problema pelo valor padronizado.\n",
    "    \n",
    "    Args: \n",
    "        value: código postal.\n",
    "        \n",
    "    Returns: \n",
    "        Se o código postal informado estiver fora do padrão, então será ignorado\n",
    "        e irá retornar None.\n",
    "    \n",
    "    \"\"\"\n",
    "    if postal_code_re.match(value):\n",
    "        return value\n",
    "    else:\n",
    "        v = value.split()\n",
    "        if len(v) > 1:\n",
    "            return v[1]\n",
    "        elif 'MA' in v[0]:\n",
    "            return None\n",
    "        else:\n",
    "            return v[0]\n",
    "\n",
    "\n",
    "def audit_fix_postal_code(filename, pattern_regex):\n",
    "    elements = []\n",
    "    for elem in get_element(filename, tags=('tag'), verify_tags = True):\n",
    "        if is_postal_code(elem):\n",
    "            elements.append(elem.get('v'))\n",
    "    return elements\n",
    "\n",
    "elements = audit_fix_postal_code(osm_file, postal_code_re)\n",
    "\n",
    "for value in elements[0:15]:\n",
    "    better_value = update_postal_code(value)\n",
    "    print( value, \"=>\", better_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparando-se para o Banco de Dados - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de importar os dados no MongoDB, precisamos realizar uma limpeza nos problemas encontrados na auditoria e estrutrar os dados de uma forma que facilite sua utilização posteriormente. Como o MongoDB trabalha com dados no formato JSON, será necessário converter de XML para JSON.\n",
    "\n",
    "Os seguintes passos devem ser realizados:\n",
    "- Processar apenas duas tags de nível superior: \"node\" and \"way\"\n",
    "- Todos os atributos de \"node\" e \"way\" devem ser convertidos em dicionários, Exceto:\n",
    "    - Os atributos de CREATED array deve ser adicionado sob a chave \"created\"\n",
    "    - Os atributos de latitude e longitude deve ser adicionado no array \"pos\",\n",
    "      para uso de indexação geoespacial. Certifique-se de que os valores são floats\n",
    "      e não Strings. \n",
    "- Se a tag de segundo nível \"k\" possuir valores problemáticos, ela deve ser ignorada.\n",
    "- Se a tag de segundo nível \"k começar com \"addr:\", ela deve ser adicionada ao dicionário \"address\"\n",
    "- Se a tag de segundo nível \"k\" não começar com \"addr:\", mas tiver \":\", você pode processar ela da forma que se sentir melhor.\n",
    "- Se tiver um segundo \":\" que separa o tipo/direção de uma rua,  a tag deve ser ignorada, por exemplo:\n",
    "\n",
    "< tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "\n",
    "< tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "\n",
    "< tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "\n",
    "< tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "\n",
    "< tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "\n",
    "< tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "\n",
    "  Deve ser transformado em:\n",
    "\n",
    "{...\n",
    "\n",
    "    \"address\": {\n",
    "\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "    \n",
    "}\n",
    "\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "\n",
    "}\n",
    "\n",
    "- Para \"way\" especificamente:\n",
    "\n",
    "  < nd ref=\"305896090\"/> \n",
    "  \n",
    "  < nd ref=\"1719825889\"/>\n",
    "\n",
    "Deve ser transformado em:\n",
    "\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "\n",
    "\n",
    "Ao final da limpeza e modelagem, os dados devem apresentar o seguinte formato:\n",
    "\n",
    "\n",
    "{\n",
    "\n",
    "    \"id\": \"2406124091\", \n",
    "    \"type: \"node\",\n",
    "    \"visible\":\"true\",\n",
    "    \"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "    \"pos\": [41.9757030, -87.6921867],\n",
    "    \"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "    \"amenity\": \"restaurant\",\n",
    "    \"cuisine\": \"mexican\",\n",
    "    \"name\": \"La Cabana De Don Luis\",\n",
    "    \"phone\": \"1 (773)-271-5176\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created': {'changeset': '106539',\n",
      "              'timestamp': '2007-06-21T10:06:54Z',\n",
      "              'uid': '8609',\n",
      "              'user': 'ewedistrict',\n",
      "              'version': '1'},\n",
      "  'id': '30731187',\n",
      "  'pos': [42.3788605, -71.039153],\n",
      "  'type': 'node'},\n",
      " {'amenity': 'restaurant',\n",
      "  'created': {'changeset': '39424017',\n",
      "              'timestamp': '2016-05-19T13:06:19Z',\n",
      "              'uid': '443130',\n",
      "              'user': 'Alan Bragg',\n",
      "              'version': '8'},\n",
      "  'id': '31419556',\n",
      "  'name': 'Firebrand Saints',\n",
      "  'pos': [42.3624561, -71.0833314],\n",
      "  'type': 'node'},\n",
      " {'created': {'changeset': '55231705',\n",
      "              'timestamp': '2018-01-07T10:20:08Z',\n",
      "              'uid': '165061',\n",
      "              'user': 'mapper999',\n",
      "              'version': '10'},\n",
      "  'description': 'Outbound only',\n",
      "  'id': '31419650',\n",
      "  'operator': 'Massachusetts Bay Transportation Authority',\n",
      "  'pos': [42.3627265, -71.0861277],\n",
      "  'railway': 'subway_entrance',\n",
      "  'type': 'node',\n",
      "  'url': 'http://www.mbta.com/schedules_and_maps/subway/lines/stations/?stopId=12412'}]\n"
     ]
    }
   ],
   "source": [
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "ADDRESS = [ \"housenumber\", \"postcode\", \"street\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\"Modela um elemento dentro do dicionário.\n",
    "    \n",
    "    Converte um elemento xml em um dicionário. \n",
    "    \n",
    "    Returns: \n",
    "            Um dicionário com as informações estruturadas\n",
    "    \n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node[\"type\"] = element.tag\n",
    "        if \"lat\" in element.attrib and \"lon\" in element.attrib:\n",
    "            node[\"pos\"] = [float(element.get('lat')), float(element.get('lon'))]\n",
    "            \n",
    "        for attr in element.attrib:\n",
    "            if attr in ['lat', 'lon']:\n",
    "                continue\n",
    "            elif attr in CREATED:\n",
    "                if \"created\" not in node:\n",
    "                    node[\"created\"] = {}\n",
    "                node[\"created\"][attr] = element.get(attr)\n",
    "            else:\n",
    "                node[attr] = element.get(attr)\n",
    "                \n",
    "        address_dic = {}\n",
    "        building_dic = {}\n",
    "        mapper_second_level_elements(element, node, address_dic, building_dic)\n",
    "        add_addres(address_dic, node)\n",
    "        add_building(building_dic, node)\n",
    "        \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_addres(address_dic, node):\n",
    "    \"\"\"Adiciona dados de endereço no elemento principal.\n",
    "    \n",
    "    Caso existam dados de endereço nos elementos de segundo nível,\n",
    "    estes serão adionados ao elemento principal como um atributo.\n",
    "    \n",
    "    Args: \n",
    "        address_dic: dicionário com dados de endereço\n",
    "        node: dicinário que contém as informações do elemento.\n",
    "    \n",
    "    \"\"\"\n",
    "    if  len(address_dic) > 0:\n",
    "        node[\"address\"] = {}\n",
    "        for key in ADDRESS:\n",
    "            if key in address_dic:\n",
    "                node[\"address\"][key] = address_dic[key]\n",
    "\n",
    "def add_building(building_dic, node):\n",
    "    \"\"\"Adiciona dados da construção no elemento principal.\n",
    "    \"\"\"\n",
    "    if len(building_dic) > 0:\n",
    "        node[\"building\"] = building_dic\n",
    "        \n",
    "def mapper_second_level_elements(element, node, address_dic, building_dic):\n",
    "    \"\"\"Responsável por navegar entre as tags de segundo nível do elemento principal.\n",
    "    \n",
    "    Realiza iteração entre os elementos de segundo nível, a fim de estruturar e \n",
    "    armazenar suas informações.\n",
    "    \n",
    "    Args: \n",
    "        element: elemento de nível superior.\n",
    "        node: dicinário que contém as informações do elemento.\n",
    "        address_dic: dionário que armazenará os dados de endereço.\n",
    "        building_dic: dicionário que armazenará os dados da construção.\n",
    "    \n",
    "    \"\"\"\n",
    "    for elem in element:\n",
    "        if elem.tag == 'nd':\n",
    "            mapper_nd(node, elem)\n",
    "        if elem.tag == 'tag' and is_valid_tag(elem):\n",
    "            mapper_tag(node, elem, address_dic, building_dic)\n",
    "                \n",
    "def mapper_tag(node, elem, address, building):\n",
    "    \"\"\"Extrai as informações da tag e separa de acordo com o tipo.\n",
    "    \n",
    "    Args: \n",
    "        elem: tag que terá seus dados extraídos.\n",
    "        node: dicinário que contém as informações do elemento.\n",
    "        address_dic: dionário que armazenará os dados de endereço.\n",
    "        building_dic: dicionário que armazenará os dados da construção.\n",
    "    \n",
    "    \"\"\"\n",
    "    if \"address\" in elem.get('k'):\n",
    "        return\n",
    "    elif 'addr:' in elem.get('k'):\n",
    "        mapper_addr(elem, address)\n",
    "    elif 'building' in elem.get('k'):\n",
    "        mapper_building(elem, building)\n",
    "    else:\n",
    "        node[elem.get('k')] = elem.get('v')\n",
    " \n",
    "\n",
    "def mapper_building(elem, building):\n",
    "    \"\"\"Extrai as informações do elemento do tipo tag e com valor k =\"building...\n",
    "    \n",
    "    Args: \n",
    "        elem: tag que terá seus dados extraídos.\n",
    "        building_dic: dicionário que armazenará os dados da construção.\n",
    "    \n",
    "    \"\"\"\n",
    "    k = elem.get('k')\n",
    "    v = elem.get('v')\n",
    "    if 'building:' in k:\n",
    "        k = k.replace('building:', '')\n",
    "        building[k] = v\n",
    "    else:\n",
    "        building[k] = v\n",
    "\n",
    "def mapper_addr(elem, address):\n",
    "    \"\"\"Extrai as informações do elemento do tipo tag e com valor k =\"addr...\n",
    "    \n",
    "    Args: \n",
    "        elem: tag que terá seus dados extraídos.\n",
    "        address: dicionário que armazenará os dados do endereço.\n",
    "    \n",
    "    \"\"\"\n",
    "    k = elem.get('k')\n",
    "    v = elem.get('v')\n",
    "    k = k.replace('addr:', '')\n",
    "    if is_postal_code(elem):\n",
    "        address[k] = update_postal_code(v)\n",
    "    elif \"street\" in k:\n",
    "        k = k.replace('street:', '')\n",
    "        if k in ADDRESS:\n",
    "            address[k] = update_name(v, mapping_street)\n",
    "    else:\n",
    "        if k in ADDRESS:\n",
    "            address[k] = v\n",
    "\n",
    "def mapper_nd(node, elem):\n",
    "    \"\"\"Extrai as informações do elemento do tipo nd.\n",
    "    \n",
    "    Args: \n",
    "        elem: tag que terá seus dados extraídos.\n",
    "        node: dicionário que armazenará o valor de ref.\n",
    "    \n",
    "    \"\"\"\n",
    "    if \"node_refs\" not in node:\n",
    "        node[\"node_refs\"] = []\n",
    "    if 'ref' in elem.attrib:\n",
    "        node[\"node_refs\"].append(elem.get(\"ref\"))\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    \"\"\"Processa o mapa e converte de XML para JSON.\n",
    "    \n",
    "     Args: \n",
    "        file_in: mapa que será processado e convertido em JSON.\n",
    "        pretty: Se True, irá adicionar espaços adionais no arquivo de saída\n",
    "    \n",
    "    \"\"\"\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = process_map(osm_file)\n",
    "pprint.pprint(data[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visão Geral dos Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seção demonstrará algumas estatísticas básicas sobre os dados, após importá-los no MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Importando dados no MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a6e344a18f0d32fb42da9a7'), 'type': 'node', 'pos': [42.3788605, -71.039153], 'id': '30731187', 'created': {'version': '1', 'timestamp': '2007-06-21T10:06:54Z', 'changeset': '106539', 'uid': '8609', 'user': 'ewedistrict'}}\n"
     ]
    }
   ],
   "source": [
    "data = []    \n",
    "with open('boston.osm.json') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "db.streetmap.insert_many(data)\n",
    "print( db.streetmap.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Tamanho dos arquivos\n",
    "\n",
    "    boston.osm................ 76MB\n",
    "    boston.osm.json........... 83.5MB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Número de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 779976 documentos cadastrados\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} documentos cadastrados\".format(db.streetmap.find().count())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Número de nós e caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 335305 nodes cadastrados\n",
      "Existem 54591 ways cadastrados\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} nodes cadastrados\".format(db.streetmap.find({\"type\" : \"node\"}).count()))\n",
    "print(\"Existem {} ways cadastrados\".format(db.streetmap.find({\"type\" : \"way\"}).count())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Número de usuários únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 906 usuários cadastrados\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} usuários cadastrados\".format(len(db.streetmap.distinct(\"created.user\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Número de dormitórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 49 dormitórios cadastrados\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} dormitórios cadastrados\".format(db.streetmap.find({'building.building': \"dormitory\"}).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Número de universidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 175 universidades cadastradas\n"
     ]
    }
   ],
   "source": [
    "print(\"Existem {} universidades cadastradas\".format(db.streetmap.find({'building.building': \"university\"}).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 Lista dos 10 usuários que mais contribuíram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'crschmidt', 'count': 182410},\n",
      " {'_id': 'jremillard-massgis', 'count': 40533},\n",
      " {'_id': 'wambag', 'count': 26930},\n",
      " {'_id': 'morganwahl', 'count': 23147},\n",
      " {'_id': 'ryebread', 'count': 18951},\n",
      " {'_id': 'OceanVortex', 'count': 13009},\n",
      " {'_id': 'mapper999', 'count': 9411},\n",
      " {'_id': 'cspanring', 'count': 5687},\n",
      " {'_id': 'JasonWoof', 'count': 4651},\n",
      " {'_id': 'synack', 'count': 4211}]\n"
     ]
    }
   ],
   "source": [
    "group = {\"$group\" : {\"_id\" : \"$created.user\", \"count\": {\"$sum\": 1}}}\n",
    "sort  = {\"$sort\": {\"count\": -1}}\n",
    "limit = {\"$limit\": 10}\n",
    "pipeline = [group, sort, limit]\n",
    "\n",
    "lista = db.streetmap.aggregate(pipeline)\n",
    "\n",
    "pprint.pprint(list(lista))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9 Lista das 10 origens que mais contribuíram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 376919},\n",
      " {'_id': 'massgis_import_v0.1_20071008193615', 'count': 5595},\n",
      " {'_id': 'massgis_import_v0.1_20071008165629', 'count': 2282},\n",
      " {'_id': 'massdot_import_081211', 'count': 844},\n",
      " {'_id': 'massgis_import_v0.1_20071009093301', 'count': 769},\n",
      " {'_id': 'Bing', 'count': 748},\n",
      " {'_id': 'USGS Geonames', 'count': 333},\n",
      " {'_id': 'massgis_import_v0.1_20071013192438', 'count': 284},\n",
      " {'_id': 'massgis_import_v0.1_20071009094247', 'count': 282},\n",
      " {'_id': 'massgis_import_v0.1_20071008141127', 'count': 262}]\n"
     ]
    }
   ],
   "source": [
    "group = {\"$group\" : {\"_id\" : \"$source\", \"count\": {\"$sum\": 1}}}\n",
    "sort  = {\"$sort\": {\"count\": -1}}\n",
    "limit = {\"$limit\": 10}\n",
    "pipeline = [group, sort, limit]\n",
    "\n",
    "lista = db.streetmap.aggregate(pipeline)\n",
    "\n",
    "pprint.pprint(list(lista))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outras ideias sobre os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar os dados, me deparei com alguns problemas na estruturação e nos valores encontrados para alguns campos. O problema que chamou mais a atenção, foi o fato de que em alguns elementos existir a tag \"address\" com o agrupamento das informações de endereço e sem padrão algum. Eu recomendaria incentivar a não utilização dessa tag e estruturar os dados de endereço somente na tag \"addr\" como vimos em algumas entradas. Outra recomendação seria utilizar um xml com definição de tipos, a fim de evitar problemas com dados sujos. Pensando nas contribuições dos registros, podemos observar que 10 usuários contribuíram com cerca de 50% dos dados, como nem todas as pessoas tem conhecimento técnico para ficar enviando dados para atualizar os registros, eu recomendaria buscar parceria com redes sociais e outros aplicativos para atualizar os dados por meio de marcação das fotos nos locais ou recomendações.\n",
    "\n",
    "1. Agrupamento das informações de endereço na tag \"address\". \n",
    "    - **Solução**: incentivar a não utilização dessa tag e estruturar os dados de endereço somente na tag \"addr\" como vimos em algumas entradas. \n",
    "        - **Benefícios:**\n",
    "            - Facilidade na extração das informações de endereço nas tags estruturados.\n",
    "        - **Problemas esperados:**\n",
    "            - Revisão nos programas que realizavam extração das informações da tag \"adress\".\n",
    "2. Tipos de dados incompativeis. Ex: código postal: 'MA 02116'        \n",
    "    - **Solução:** utilizar um xml com definição de tipos.\n",
    "        - **Benefícios:**\n",
    "            - Dados mais padronizados e fáceis de processar\n",
    "            - Eevitará problemas com dados sujos.\n",
    "        - **Problemas esperados:**\n",
    "            - Diminuição da flexibilidade de implementação dos programas.\n",
    "            - Aumentará o tempo para o desenvolvimento das soluções.\n",
    "3. Poucas usuários contribuem com a atualização dos dados:\n",
    "    - **Solução:** buscar parcerias com redes sociais para a inclusão de dados no OSM.\n",
    "        - **Benefícios:**\n",
    "            - Aumento direto nas contribuições dos dados, devido ao grande número de usuários nas redes sociais.\n",
    "            - Dados mais confiáveis.\n",
    "        - **Problemas esperados:**\n",
    "            - Melhoria nas infraestrutura dos servidores, devido a grande quantidade de requisições com origem nas redes sociais.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, escolhi analisar a área de Boston, EUA, e foi realizado o processo de limpeza de dados. Na fase de auditoria, nos encontrados alguns problemas como códigos postais inválidos e diversas abreviações diferentes para o mesmo endereço. Em seguida, realizamos as devidas correções e importamos os dados limpos no MongoDB. \n",
    "Para evitar este grande esforço para: auditar, limpar e resubmeter os dados, deveria padronizar a entrada de dados por Bots inteligentes ou por órgãos como o MassGIS - Escritório de Informação Geográfica e Ambiental da Commonwealth, a fim de garantir dados mais limpos que os inseridos manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/1945920/why-doesnt-os-path-join-work-in-this-case\n",
    "\n",
    "http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "\n",
    "https://wiki.openstreetmap.org/wiki/MassGIS\n",
    "\n",
    "https://stackoverflow.com/questions/28155857/mongodb-find-query-return-only-unique-values-no-duplicates\n",
    "\n",
    "https://www.safaribooksonline.com/library/view/regular-expressions-cookbook/9781449327453/ch04s14.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
